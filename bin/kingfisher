#!/usr/bin/env python3

__author__ = "Ben Woodcroft"
__copyright__ = "Copyright 2021"
__credits__ = ["Ben Woodcroft"]
__license__ = "GPL3+"
__maintainer__ = "Ben Woodcroft"
__email__ = "b.woodcroft near qut.edu.au"
__status__ = "Development"

import argparse
import logging
import subprocess
import os
import sys
import warnings
import tempfile
import json

import extern
from extern import ExternCalledProcessError

sys.path = [os.path.join(os.path.dirname(os.path.realpath(__file__)),'..')] + sys.path
from kingfisher.ena import AsperaEnaDownloader

class NcbiAwsLocation:
    def __init__(self, j):
        self.j = j

    def service(self):
        if self.j['service'] == 's3':
            if 'sra-pub-run-odp' in self.j['link']:
                return 's3-odp'
            else:
                return 's3-pay'
        elif self.j['service'] == 'sra-ncbi':
            return 'sra'

    def s3_command_prefix(self, run_id):
        if self.service() == 's3-pay':
            return 'aws s3api get-object --bucket {} --key {} --request-payer requester'.format(
                self.j['bucket'], self.j['key']
            )
        elif self.service() == 's3-odp':
            return 'aws s3 cp s3://sra-pub-run-odp/sra/{}/{}'.format(run_id, run_id)
        else:
            raise Exception("Unexpected json location found: {}", self.j)

    def link(self):
        return self.j['link']


class NcbiGcpLocation:
    def __init__(self, j):
        self.j = j

    def gs_path(self):
        return 'gs://{}/{}'.format(self.j['bucket'], self.j['key'])

def get_ncbi_locations(run_id, location, accept_charges_str):
    json_location_string = 'https://locate.ncbi.nlm.nih.gov/sdl/2/retrieve?location={}&acc={}&location-type=forced&accept-charges={}'.format(
        location, run_id, accept_charges_str
    )
    json_response = extern.run('curl -q \'{}\''.format(json_location_string))
    logging.debug("Got location JSON: {}".format(json_response))

    j = json.loads(json_response)
    if 'version' not in j or j['version'] != '2':
        raise Exception(
            "Unexpected json location string returned: {}", json_location_string)
    # TODO: Assumes there is only 1 result, which is all I've ever seen
    return flatten_list(list([list([l for l in f['locations']]) for f in j['result'][0]['files']]))

def get_ncbi_aws_locations(run_id):
    return list([NcbiAwsLocation(l) for l in get_ncbi_locations(run_id, 's3.us-east-1', 'aws')])

def get_ncbi_gcp_locations(run_id):
    return list([NcbiGcpLocation(l) for l in get_ncbi_locations(run_id, 'gs.us', 'gcp')])

def flatten_list(_2d_list):
    flat_list = []
    # Iterate through the outer list
    for element in _2d_list:
        if type(element) is list:
            # If the element is of type list, iterate through the sublist
            for item in element:
                flat_list.append(item)
        else:
            flat_list.append(element)
    return flat_list

class DownloadMethodFailed(Exception):
    pass

if __name__ == '__main__':
    parser= argparse.ArgumentParser(
        description='Download and extract FASTQ files from the NCBI SRA or ENA databases. \
            Requires the SRA toolkit to be installed, available at \
            https://github.com/ncbi/sra-tools - a list of conda \
            requirements (excluding AWS\' CLIv2, Google Cloud\'s gsutil/gcloud and Aspera connect) \
            is: python extern pigz sra-tools')
    parser.add_argument(
        '--run-identifier','--run_identifier','-r',
        help='Run number to download e.g. ERR1739691',
        required=True)
    parser.add_argument(
        '-m','--download_methods', '--download-methods',
        nargs='+',
        help='How to download .sra file. If multiple are specified, each is tried in turn until one works.',
        choices=['aws-http', 'prefetch', 'aws-cp', 'gcp-cp', 'ena-ascp'], required=True)
    parser.add_argument(
        '--output_format_possibilities', '--output-format-possibilities',
        nargs='+',
        help='Allowable output formats. If more than one is specified, downloaded data will processed as little as possible.',
        choices=['sra', 'fastq', 'fastq.gz'],
        default=['fastq','fastq.gz'])
    parser.add_argument(
        '--gcp_project','--gcp-project',
        help='Downloading from Google Cloud buckets require a Google project to charge '
        '(they are requester-pays) e.g. \'my-project\'. This can alternately be set '
        'beforehand using \'gcloud config set project PROJECT_ID\' '
        '[default: value of `gcloud config get-value project` command]')
    parser.add_argument(
        '--allow_paid', '--allow-paid',
        help='Allow AWS and GCP to cp from retriever-pays s3 and GCP buckets',
        action='store_true')

    parser.add_argument('--debug', help='output debug information',
                        action="store_true", default=False)
    parser.add_argument('--quiet', help='only output errors',
                        action="store_true", default=False)
    args= parser.parse_args()

    if args.debug:
        loglevel= logging.DEBUG
    elif args.quiet:
        loglevel= logging.ERROR
    else:
        loglevel= logging.INFO
    logging.basicConfig(
        level=loglevel, format='%(asctime)s %(levelname)s: %(message)s',
        datefmt='%m/%d/%Y %I:%M:%S %p')

    if args.allow_paid:
        allowable_sources = ('s3-pay', 's3-odp', 'gcp-cp')
    else:
        allowable_sources = ('s3-odp')


    output_files = []

    # Checking for already existing files
    skip_download_and_extraction = False
    for file_type in args.output_format_possibilities:
        if file_type == 'sra':
            path = "{}.{}".format(args.run_identifier, file_type)
            if os.path.exists(path):
                skip_download_and_extraction = True
                output_files.append(path)
                logging.info(
                    "Skipping download of {} as an output file already appears to exist, as file {}".format(args.run_identifier, path))
        elif file_type == 'fastq':
            possibilities = ['{}.fastq'.format(args.run_identifier),'{}_1.fastq'.format(args.run_identifier),'{}_2.fastq'.format(args.run_identifier)]
            for path in possibilities:
                if os.path.exists(path):
                    skip_download_and_extraction = True
                    output_files.append(path)
                    logging.info(
                        "Skipping download of {} as an output file already appears to exist, as file {}".format(args.run_identifier, path))
        elif file_type == 'fastq.gz':
            possibilities = ['{}.fastq.gz'.format(args.run_identifier),'{}_1.fastq.gz'.format(args.run_identifier),'{}_2.fastq.gz'.format(args.run_identifier)]
            for path in possibilities:
                if os.path.exists(path):
                    skip_download_and_extraction = True
                    output_files.append(path)
                    logging.info(
                        "Skipping download of {} as an output file already appears to exist, as file {}".format(args.run_identifier, path))
        else:
            raise Exception("Programming error")

    if 'ena-ascp' in args.download_methods and 'fastq.gz' not in args.output_format_possibilities:
        raise Exception("The \'ena-ascp\' method must be used with fastq.gz as an output format possibility.")

    downloaded_files = None
    if not skip_download_and_extraction:
        # Download phase
        worked = False
        for method in args.download_methods:
            logging.info("Attempting download method {} ..".format(method))
            if method == 'prefetch':
                try:
                    extern.run("prefetch -o {}.sra {}".format(
                        args.run_identifier, args.run_identifier))
                    downloaded_files = '{}.sra'.format(args.run_identifier)
                except ExternCalledProcessError as e:
                    logging.warning("Method {} failed: Error was: {}".format(method, e))
                
            elif method == 'aws-http':
                locations = get_ncbi_aws_locations(args.run_identifier)
                odp_http_locations = list([l.link for l in locations if l.service == 'sra-odp'])
                if len(odp_http_locations) > 0:
                    logging.info("Found ODP link {}".format(odp_http_locations[0]))
                    odp_link = odp_http_locations[0]

                    logging.info(
                        "Downloading .SRA file from AWS Open Data Program HTTP link ..")
                    try:
                        extern.run("curl -q -o {}.sra '{}'".format(args.run_identifier, odp_link))
                        logging.info("Download finished")
                        downloaded_files = '{}.sra'.format(args.run_identifier)
                    except ExternCalledProcessError as e:
                        logging.warning("Method {} failed: Error was: {}".format(method, e))
                else:
                    logging.warning("Method {} failed: No ODP URL could be found".format(method))

            elif method == 'aws-cp':
                locations = get_ncbi_aws_locations(args.run_identifier) 
                s3_locations = list([l for l in locations if l.service() in allowable_sources])

                if len(s3_locations) > 0:
                    s3_location = s3_locations[0]
                    logging.info("Found s3 link {}".format(s3_location.j['link']))

                    command = '{} {}.sra'.format(
                        s3_location.s3_command_prefix(args.run_identifier), args.run_identifier
                    )
                    logging.info("Downloading from S3..")
                    try:
                        extern.run(command)
                        downloaded_files = '{}.sra'.format(args.run_identifier)
                    except ExternCalledProcessError as e:
                        logging.warning("Method {} failed: Error was: {}".format(method, e))
                else:
                    logging.warning("Method {} failed: No S3 location could be found".format(method))

            elif method == 'gcp-cp':
                if 'gcp-cp' in allowable_sources:
                    locations = get_ncbi_gcp_locations(args.run_identifier)
                    if len(locations) > 0:
                        loc = locations[0]
                        command = 'gsutil'
                        if args.gcp_project:
                            command = command + " -u {}".format(args.gcp_project)
                        else:
                            logging.info("Finding Google cloud project to charge")
                            project_id = extern.run('gcloud config get-value project').strip()
                            logging.info("Charging to project \'{}\'".format(project_id))
                            command = command + " -u {}".format(project_id)
                        command += ' cp {} {}.sra'.format(
                            loc.gs_path(), args.run_identifier
                        )
                        logging.info("Downloading from GCP..")
                        try:
                            extern.run(command)
                            downloaded_files = '{}.sra'.format(args.run_identifier)
                        except ExternCalledProcessError as e:
                            logging.warning("Method {} failed: Error was: {}".format(method, e))
                    else:
                        logging.warning("Method {} failed: No GCP location could be found".format(method))
                else:
                    logging.warn("Not using method gcp-cp as --allow-paid was not specified")

            elif method == 'ena-ascp':
                result = AsperaEnaDownloader().download(args.run_identifier, '.')
                if result is not False:
                    downloaded_files = result

            else:
                raise Exception("Unknown method: {}".format(method))
            
            if downloaded_files is not None:
                logging.info("Method {} worked.".format(method))
                break
            else:
                logging.warning("Method {} failed".format(method))

        if downloaded_files is None:
            raise Exception("No more specified download methods, cannot continue")

    # Extraction/conversion phase
    if not skip_download_and_extraction:
        if downloaded_files == ['{}.sra'.format(args.run_identifier)]:
            if 'sra' not in args.output_format_possibilities:
                extern.run("fasterq-dump ./{}.sra".format(args.run_identifier))
                os.remove('{}.sra'.format(args.run_identifier))

                if 'fastq' not in args.output_format_possibilities:
                    for fq in ['x_1.fastq','x_2.fastq','x.fastq']:
                        f = fq.replace('x',args.run_identifier)
                        if os.path.exists(f):
                            logging.debug("Compressing {} with pigz ..".format(f))
                            extern.run("pigz {}".format(f))
                            output_files.append("{}.gz".format(f))
                else:
                    for fq in ['x_1.fastq','x_2.fastq','x.fastq']:
                        f = fq.replace('x',args.run_identifier)
                        if os.path.exists(f):
                            output_files.append(f)
            else:
                output_files.append("{}.sra".format(args.run_identifier))
        else:
            if 'fastq.gz' not in args.output_format_possibilities:
                raise Exception("Programming error")
            output_files = downloaded_files

    logging.info("Output files: {}".format(', '.join(output_files)))

logging.info("All done.")
